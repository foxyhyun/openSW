{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5514cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import openpyxl\n",
    "import urllib\n",
    "from urllib import parse\n",
    "import lxml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1c7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scale(inp):# 환율데이터 표본적어서 *10\n",
    "    result = []\n",
    "    for i in inp:\n",
    "        result.append(((i-np.mean(inp))/np.var(inp))*10)\n",
    "    return result\n",
    "def normalize(inp):# *10안함\n",
    "    result = []\n",
    "    for i in inp:\n",
    "        result.append(((i-np.mean(inp))/np.var(inp)))\n",
    "    return result\n",
    "\n",
    "class Stock:\n",
    "    \n",
    "    Exchange='./Data/Exchange.csv' #객체가 공통으로 사용할 환율 데이터 (동적크롤링할줄몰라서 csv로 받아옴)\n",
    "    \n",
    "    def __init__(self,code):\n",
    "        self.code=code\n",
    "    \n",
    "    @staticmethod\n",
    "    def exchangeRate():  ##1달간격의 환율의 종가데이터  1행배열 57요소( 18.05.01~  23.01.01) 배열로 출력 SIZE(1,57)\n",
    "        csv = pd.read_csv(Stock.Exchange,encoding='utf8')\n",
    "        #print(csv)  환율 전체데이터 확인하기            \n",
    "        csv = np.array(csv)\n",
    "        data=[]\n",
    "        for i in range(len(csv)):   \n",
    "            fnum=\"\"\n",
    "            for j in csv[i][1]:\n",
    "                if(j == ','):\n",
    "                    continue\n",
    "                fnum+=j\n",
    "            data.append(float(fnum))\n",
    "        data = np.array(data)\n",
    "        data = data.astype('float32')\n",
    "        data = normalize_scale(data) \n",
    "        return data\n",
    "\n",
    "    def idxNorm(self):##ROA, ROE, EPS, BPS, DPS, PER, PBR의 각 항목당 (2018.12 ~ 2023.12)의 데이터 6개 갖음 SIZE(7,8)\n",
    "        get_param = {\n",
    "            'pGB':1,\n",
    "            'gicode':'A%s'%(self.code),\n",
    "            'cID':'',\n",
    "            'MenuYn':'Y',\n",
    "            'ReportGB':'',\n",
    "            'NewMenuID':101,\n",
    "            'stkGb':701,\n",
    "        }\n",
    "        get_param = parse.urlencode(get_param)\n",
    "        url=\"http://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?%s\"%(get_param)\n",
    "        tables = pd.read_html(url, header=0,encoding='utf-8')\n",
    "        sit=np.array(tables[11]) \n",
    "\n",
    "        data=[]#정규화 시작\n",
    "\n",
    "        for i in range(7):\n",
    "            crw=[]\n",
    "            if (i == 4): continue\n",
    "            for j in range(7):\n",
    "                \n",
    "                if(sit[17+i][j+1] != sit[17+i][j+1]):\n",
    "                    idx =  (float(sit[17+i][j]) + float(sit[17+i][j+2]))/2.0\n",
    "                    crw.append(idx)\n",
    "                    continue\n",
    "                idx = float(sit[17+i][j+1])\n",
    "                crw.append(idx)\n",
    "            data.append(normalize(crw))\n",
    "        data=np.array(data)\n",
    "        return data\n",
    "    \n",
    "    def priceList(self):\n",
    "        csv = pd.read_csv('./Data/주식가격/%s.csv'%(self.code))\n",
    "        cut_csv = csv[:][:1148]\n",
    "        arr = np.array(cut_csv)\n",
    "        array = arr[:,1]\n",
    "        array = array/10000\n",
    "        array = np.array(array)\n",
    "        close = array.reshape(-1,1)\n",
    "        return close\n",
    "\n",
    "    def showChart(self): ##종목코드의 제무재표를 나타내는 함수\n",
    "        get_param = {\n",
    "            'pGB':1,\n",
    "            'gicode':'A%s'%(self.code),\n",
    "            'cID':'',\n",
    "            'MenuYn':'Y',\n",
    "            'ReportGB':'',\n",
    "            'NewMenuID':101,\n",
    "            'stkGb':701,\n",
    "        }\n",
    "        get_param = parse.urlencode(get_param)\n",
    "        url=\"http://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?%s\"%(get_param)\n",
    "        tables = pd.read_html(url, header=0,encoding='utf-8')\n",
    "        return tables[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe027455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatData(a, data):\n",
    "    a2023 = a[:-1147]\n",
    "    a2022 = a[-1147:-901]\n",
    "    a2021 = a[-901:-653]\n",
    "    a2020 = a[-653:-405]\n",
    "    a2019 = a[-405:-159]\n",
    "    a2018 = a[-159:len(a)]\n",
    "    \n",
    "    data2023 = np.full((len(a2023),6), data[:,5])\n",
    "    data2022 = np.full((len(a2022),6), data[:,4])\n",
    "    data2021 = np.full((len(a2021),6), data[:,3])\n",
    "    data2020 = np.full((len(a2020),6), data[:,2])\n",
    "    data2019 = np.full((len(a2019),6), data[:,1])\n",
    "    data2018 = np.full((len(a2018),6), data[:,0])\n",
    "    \n",
    "    data1 = data2023\n",
    "    data1 = np.concatenate((np.full((len(a2023),6), data[:,5]),\n",
    "                            np.full((len(a2022),6), data[:,4]),\n",
    "                            np.full((len(a2021),6), data[:,3]),\n",
    "                            np.full((len(a2020),6), data[:,2]),\n",
    "                            np.full((len(a2019),6), data[:,1]),\n",
    "                            np.full((len(a2018),6), data[:,0])), axis=0)\n",
    "    arr = np.concatenate((a, data1), axis=1)\n",
    "    array = np.array(arr)\n",
    "    \n",
    "    er = Stock.exchangeRate()\n",
    "    er = np.array(er).reshape(-1, 1)\n",
    "    \n",
    "    exchange = np.full((1,1), er[-57])\n",
    "    exchange = np.concatenate((exchange, np.full((21,1), er[-56]),\n",
    "                               np.full((22,1), er[-55]),\n",
    "                               np.full((19,1), er[-54]),\n",
    "                               np.full((20,1), er[-53]),\n",
    "                               np.full((22,1), er[-52]),\n",
    "                               np.full((21,1), er[-51]),\n",
    "                               np.full((20,1), er[-50]),\n",
    "                               np.full((21,1), er[-49]),\n",
    "                               np.full((21,1), er[-48]),\n",
    "                               np.full((21,1), er[-47]),\n",
    "                               np.full((18,1), er[-46]),\n",
    "                               np.full((20,1), er[-45]),\n",
    "                               np.full((22,1), er[-44]),\n",
    "                               np.full((22,1), er[-43]),\n",
    "                               np.full((19,1), er[-42]),\n",
    "                               np.full((19,1), er[-41]),\n",
    "                               np.full((21,1), er[-40]),\n",
    "                               np.full((22,1), er[-39]),\n",
    "                               np.full((22,1), er[-38]),\n",
    "                               np.full((19,1), er[-37]),\n",
    "                               np.full((22,1), er[-36]),\n",
    "                               np.full((22,1), er[-35]),\n",
    "                               np.full((18,1), er[-34]),\n",
    "                               np.full((20,1), er[-33]),\n",
    "                               np.full((21,1), er[-32]),\n",
    "                               np.full((21,1), er[-31]),\n",
    "                               np.full((19,1), er[-30]),\n",
    "                               np.full((21,1), er[-29]),\n",
    "                               np.full((20,1), er[-28]),\n",
    "                               np.full((23,1), er[-27]),\n",
    "                               np.full((22,1), er[-26]),\n",
    "                               np.full((19,1), er[-25]),\n",
    "                               np.full((20,1), er[-24]),\n",
    "                               np.full((22,1), er[-23]),\n",
    "                               np.full((20,1), er[-22]),\n",
    "                               np.full((20,1), er[-21]),\n",
    "                               np.full((20,1), er[-20]),\n",
    "                               np.full((21,1), er[-19]),\n",
    "                               np.full((21,1), er[-18]),\n",
    "                               np.full((19,1), er[-17]),\n",
    "                               np.full((21,1), er[-16]),\n",
    "                               np.full((23,1), er[-15]),\n",
    "                               np.full((19,1), er[-14]),\n",
    "                               np.full((21,1), er[-13]),\n",
    "                               np.full((22,1), er[-12]),\n",
    "                               np.full((20,1), er[-11]),\n",
    "                               np.full((17,1), er[-10]),\n",
    "                               np.full((22,1), er[-9]),\n",
    "                               np.full((19,1), er[-8]),\n",
    "                               np.full((22,1), er[-7]),\n",
    "                               np.full((21,1), er[-6]),\n",
    "                               np.full((17,1), er[-5]),\n",
    "                               np.full((22,1), er[-4]),\n",
    "                               np.full((22,1), er[-3]),\n",
    "                               np.full((19,1), er[-2]),\n",
    "                               np.full((17,1), er[-1])), axis=0)\n",
    "    train_inputs = np.concatenate((array, exchange), axis=1)\n",
    "    return train_inputs\n",
    "def returnInputs(a,b):\n",
    "    inputs = concatData(a, b)\n",
    "    results = inputs[:-1,:].astype(float)\n",
    "    return results\n",
    "def returnLabels(a,b):\n",
    "    inputs = concatData(a, b)\n",
    "    results = inputs[1:,0].reshape(-1,1).astype(float)\n",
    "    return results\n",
    "def reverseData(arr):\n",
    "    temp = [[0] * len(arr[0]) for _ in range(len(arr))]\n",
    "    for i in range(len(arr)):\n",
    "        temp[i] = arr[len(arr)-1-i]\n",
    "    return temp\n",
    "def scaleData(a):\n",
    "    scaler = MinMaxScaler()\n",
    "    scale_cols = [0]\n",
    "    df_scaled = scaler.fit_transform(a[scale_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52844246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wjddu\\AppData\\Local\\Temp\\ipykernel_2780\\4271975719.py:70: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv('./Data/주식가격/%s.csv'%(self.code))\n",
      "C:\\Users\\wjddu\\AppData\\Local\\Temp\\ipykernel_2780\\4271975719.py:70: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv('./Data/주식가격/%s.csv'%(self.code))\n"
     ]
    }
   ],
   "source": [
    "SS = Stock('005930')\n",
    "SK = Stock('000660')\n",
    "DW=Stock('049770')\n",
    "SFA=Stock('056190')\n",
    "GB=Stock('024110')\n",
    "\n",
    "sa=SS.priceList()\n",
    "sk=SK.priceList()\n",
    "dw=DW.priceList()\n",
    "sf=SFA.priceList()\n",
    "gb=GB.priceList()\n",
    "sadata=SS.idxNorm()\n",
    "skdata=SK.idxNorm()\n",
    "dwdata=DW.idxNorm()\n",
    "sfdata=SFA.idxNorm()\n",
    "gbdata=GB.idxNorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffde786e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_inputs = []\n",
    "train_labels = []\n",
    "train_inputs.append(reverseData(returnInputs(sa, sadata)))\n",
    "train_inputs.append(reverseData(returnInputs(sk, skdata)))\n",
    "train_inputs.append(reverseData(returnInputs(dw, dwdata)))\n",
    "train_inputs.append(reverseData(returnInputs(sf, sfdata)))\n",
    "train_inputs.append(reverseData(returnInputs(gb, gbdata)))\n",
    "train_inputs = np.array(train_inputs)\n",
    "\n",
    "train_labels.append(reverseData(returnLabels(sa, sadata)))\n",
    "train_labels.append(reverseData(returnLabels(sk, skdata)))\n",
    "train_labels.append(reverseData(returnLabels(dw, dwdata)))\n",
    "train_labels.append(reverseData(returnLabels(sf, sfdata)))\n",
    "train_labels.append(reverseData(returnLabels(gb, gbdata)))\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1acf6ad3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 1147, 512)         1067008   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 128)               328192    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,395,329\n",
      "Trainable params: 1,395,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 122.9470\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 94.2252\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 67.0679\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 53.3834\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 45.9738\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 42.3492\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 40.5870\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 39.5482\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 38.4475\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 36.0689\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 29.7825\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 25.5844\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.3827\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.3986\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.1745\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.1260\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.7916\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 30.6935\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.7451\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.3064\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 42.0691\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 35.7535\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 40.5921\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 29.0140\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 50.3859\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 30.1095\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 31.6067\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 38.8978\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 44.7310\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 43.4763\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 40.4986\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 37.9993\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 38.7333\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 38.4324\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 37.8248\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 37.4093\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 36.9228\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 36.3167\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 35.6178\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 34.8237\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 34.0674\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 33.5464\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 33.2093\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 35.0100\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32.5759\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32.2106\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32.3215\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32.9431\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32.8198\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 31.6579\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 31.7077\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 30.4681\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 30.1024\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 29.1501\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 27.9806\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 27.2308\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 26.4323\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 25.5278\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.7738\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.0377\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 23.3072\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.5748\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.8538\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.1802\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.5421\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 19.9731\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 19.3430\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.7594\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.2130\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.6601\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.1312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.6165\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.1010\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.6187\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.1354\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.6879\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.2453\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.8411\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.4486\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.0885\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 12.7368\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 12.4081\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 12.0866\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.7833\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.4840\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.1986\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.9166\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.6429\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.3723\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.1064\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.8474\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5862\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.3329\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 9.1197\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9216\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.7343\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.5550\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.3900\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.2304\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.0817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x230fa5ffee0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.LSTM(512, input_shape=(train_inputs.shape[1],train_inputs.shape[2]), return_sequences=True),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(1, activation = 'relu')\n",
    "])\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.summary()\n",
    "model.fit(train_inputs, train_labels,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1485250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('stockmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12b36b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5.09        0.45111764  0.31059243 ... -0.2270406   2.01693153\n",
      "   -0.18861003]\n",
      "  [ 5.16        0.45111764  0.31059243 ... -0.2270406   2.01693153\n",
      "   -0.18861003]\n",
      "  [ 5.13        0.45111764  0.31059243 ... -0.2270406   2.01693153\n",
      "   -0.18861003]\n",
      "  ...\n",
      "  [ 5.66        0.05481708  0.03894379 ... -0.04130336  2.40506956\n",
      "    0.13651005]\n",
      "  [ 5.53        0.05481708  0.03894379 ... -0.04130336  2.40506956\n",
      "    0.13651005]\n",
      "  [ 5.55       -0.14176057 -0.09841311 ...  0.0499988  -0.6515174\n",
      "    0.15273633]]]\n",
      "1/1 [==============================] - 1s 929ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.622607]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[]\n",
    "a.append(reverseData(returnInputs(sa, sadata)))\n",
    "a = np.array(a)\n",
    "print(a)\n",
    "model.predict(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
