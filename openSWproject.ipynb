{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import openpyxl\n",
    "import urllib\n",
    "from urllib import parse\n",
    "import lxml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scale(inp):# 환율데이터 표본적어서 *10\n",
    "    result = []\n",
    "    for i in inp:\n",
    "        result.append(((i-np.mean(inp))/np.var(inp))*10)\n",
    "    return result\n",
    "def normalize(inp):# *10안함\n",
    "    result = []\n",
    "    for i in inp:\n",
    "        result.append(((i-np.mean(inp))/np.var(inp)))\n",
    "    return result\n",
    "\n",
    "class Stock:\n",
    "    \n",
    "    Exchange='./Data/Exchange.csv' #객체가 공통으로 사용할 환율 데이터 (동적크롤링할줄몰라서 csv로 받아옴)\n",
    "    \n",
    "    def __init__(self,code):\n",
    "        self.code=code\n",
    "    \n",
    "    @staticmethod\n",
    "    def exchangeRate():  ##1달간격의 환율의 종가데이터  1행배열 57요소( 18.05.01~  23.01.01) 배열로 출력 SIZE(1,57)\n",
    "        csv = pd.read_csv(Stock.Exchange,encoding='utf8')\n",
    "        #print(csv)  환율 전체데이터 확인하기            \n",
    "        csv = np.array(csv)\n",
    "        data=[]\n",
    "        for i in range(len(csv)):   \n",
    "            fnum=\"\"\n",
    "            for j in csv[i][1]:\n",
    "                if(j == ','):\n",
    "                    continue\n",
    "                fnum+=j\n",
    "            data.append(float(fnum))\n",
    "        data = np.array(data)\n",
    "        data = data.astype('float32')\n",
    "        data = normalize_scale(data) \n",
    "        return data\n",
    "\n",
    "    def idxNorm(self):##ROA, ROE, EPS, BPS, DPS, PER, PBR의 각 항목당 (2018.12 ~ 2023.12)의 데이터 6개 갖음 SIZE(7,8)\n",
    "        get_param = {\n",
    "            'pGB':1,\n",
    "            'gicode':'A%s'%(self.code),\n",
    "            'cID':'',\n",
    "            'MenuYn':'Y',\n",
    "            'ReportGB':'',\n",
    "            'NewMenuID':101,\n",
    "            'stkGb':701,\n",
    "        }\n",
    "        get_param = parse.urlencode(get_param)\n",
    "        url=\"http://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?%s\"%(get_param)\n",
    "        tables = pd.read_html(url, header=0,encoding='utf-8')\n",
    "        sit=np.array(tables[11]) \n",
    "\n",
    "        data=[]#정규화 시작\n",
    "\n",
    "        for i in range(7):\n",
    "            crw=[]\n",
    "            if (i == 4): continue\n",
    "            for j in range(7):\n",
    "                \n",
    "                if(sit[17+i][j+1] != sit[17+i][j+1]):\n",
    "                    idx =  (float(sit[17+i][j]) + float(sit[17+i][j+2]))/2.0\n",
    "                    crw.append(idx)\n",
    "                    continue\n",
    "                idx = float(sit[17+i][j+1])\n",
    "                crw.append(idx)\n",
    "            data.append(normalize(crw))\n",
    "        data=np.array(data)\n",
    "        return data\n",
    "    \n",
    "    def priceList(self):\n",
    "        csv = pd.read_csv('./Data/주식가격/%s.csv'%(self.code))\n",
    "        cut_csv = csv[:][:1148]\n",
    "        arr = np.array(cut_csv)\n",
    "        array = arr[:,1]\n",
    "        array = array/10000\n",
    "        array = np.array(array)\n",
    "        arr = array.reshape(-1,1)\n",
    "        temp = [[0] * len(arr[0]) for _ in range(len(arr))]\n",
    "        for i in range(len(arr)):\n",
    "            temp[i] = arr[len(arr)-1-i]\n",
    "        temp = np.array(temp).astype(float)\n",
    "        return temp\n",
    "        \n",
    "\n",
    "    def showChart(self): ##종목코드의 제무재표를 나타내는 함수\n",
    "        get_param = {\n",
    "            'pGB':1,\n",
    "            'gicode':'A%s'%(self.code),\n",
    "            'cID':'',\n",
    "            'MenuYn':'Y',\n",
    "            'ReportGB':'',\n",
    "            'NewMenuID':101,\n",
    "            'stkGb':701,\n",
    "        }\n",
    "        get_param = parse.urlencode(get_param)\n",
    "        url=\"http://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?%s\"%(get_param)\n",
    "        tables = pd.read_html(url, header=0,encoding='utf-8')\n",
    "        return tables[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe027455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatData(a, data):\n",
    "    a2023 = a[1147:]\n",
    "    a2022 = a[901:1147]\n",
    "    a2021 = a[653:901]\n",
    "    a2020 = a[405:653]\n",
    "    a2019 = a[159:405]\n",
    "    a2018 = a[0:159]\n",
    "    \n",
    "    data2023 = np.full((len(a2023),6), data[:,5])\n",
    "    data2022 = np.full((len(a2022),6), data[:,4])\n",
    "    data2021 = np.full((len(a2021),6), data[:,3])\n",
    "    data2020 = np.full((len(a2020),6), data[:,2])\n",
    "    data2019 = np.full((len(a2019),6), data[:,1])\n",
    "    data2018 = np.full((len(a2018),6), data[:,0])\n",
    "    \n",
    "    data1 = data2023\n",
    "    data1 = np.concatenate((np.full((len(a2023),6), data[:,5]),\n",
    "                            np.full((len(a2022),6), data[:,4]),\n",
    "                            np.full((len(a2021),6), data[:,3]),\n",
    "                            np.full((len(a2020),6), data[:,2]),\n",
    "                            np.full((len(a2019),6), data[:,1]),\n",
    "                            np.full((len(a2018),6), data[:,0])), axis=0)\n",
    "    arr = np.concatenate((a, data1), axis=1)\n",
    "    array = np.array(arr)\n",
    "    \n",
    "    er = Stock.exchangeRate()\n",
    "    er = np.array(er).reshape(-1, 1)\n",
    "    \n",
    "    exchange = np.full((1,1), er[-57])\n",
    "    exchange = np.concatenate((exchange, np.full((21,1), er[-56]),\n",
    "                               np.full((22,1), er[-55]),\n",
    "                               np.full((19,1), er[-54]),\n",
    "                               np.full((20,1), er[-53]),\n",
    "                               np.full((22,1), er[-52]),\n",
    "                               np.full((21,1), er[-51]),\n",
    "                               np.full((20,1), er[-50]),\n",
    "                               np.full((21,1), er[-49]),\n",
    "                               np.full((21,1), er[-48]),\n",
    "                               np.full((21,1), er[-47]),\n",
    "                               np.full((18,1), er[-46]),\n",
    "                               np.full((20,1), er[-45]),\n",
    "                               np.full((22,1), er[-44]),\n",
    "                               np.full((22,1), er[-43]),\n",
    "                               np.full((19,1), er[-42]),\n",
    "                               np.full((19,1), er[-41]),\n",
    "                               np.full((21,1), er[-40]),\n",
    "                               np.full((22,1), er[-39]),\n",
    "                               np.full((22,1), er[-38]),\n",
    "                               np.full((19,1), er[-37]),\n",
    "                               np.full((22,1), er[-36]),\n",
    "                               np.full((22,1), er[-35]),\n",
    "                               np.full((18,1), er[-34]),\n",
    "                               np.full((20,1), er[-33]),\n",
    "                               np.full((21,1), er[-32]),\n",
    "                               np.full((21,1), er[-31]),\n",
    "                               np.full((19,1), er[-30]),\n",
    "                               np.full((21,1), er[-29]),\n",
    "                               np.full((20,1), er[-28]),\n",
    "                               np.full((23,1), er[-27]),\n",
    "                               np.full((22,1), er[-26]),\n",
    "                               np.full((19,1), er[-25]),\n",
    "                               np.full((20,1), er[-24]),\n",
    "                               np.full((22,1), er[-23]),\n",
    "                               np.full((20,1), er[-22]),\n",
    "                               np.full((20,1), er[-21]),\n",
    "                               np.full((20,1), er[-20]),\n",
    "                               np.full((21,1), er[-19]),\n",
    "                               np.full((21,1), er[-18]),\n",
    "                               np.full((19,1), er[-17]),\n",
    "                               np.full((21,1), er[-16]),\n",
    "                               np.full((23,1), er[-15]),\n",
    "                               np.full((19,1), er[-14]),\n",
    "                               np.full((21,1), er[-13]),\n",
    "                               np.full((22,1), er[-12]),\n",
    "                               np.full((20,1), er[-11]),\n",
    "                               np.full((17,1), er[-10]),\n",
    "                               np.full((22,1), er[-9]),\n",
    "                               np.full((19,1), er[-8]),\n",
    "                               np.full((22,1), er[-7]),\n",
    "                               np.full((21,1), er[-6]),\n",
    "                               np.full((17,1), er[-5]),\n",
    "                               np.full((22,1), er[-4]),\n",
    "                               np.full((22,1), er[-3]),\n",
    "                               np.full((19,1), er[-2]),\n",
    "                               np.full((17,1), er[-1])), axis=0)\n",
    "    train_inputs = np.concatenate((array, exchange), axis=1)\n",
    "    return train_inputs\n",
    "def returnInputs(a,b):\n",
    "    inputs = concatData(a, b)\n",
    "    results = inputs[:-1,:].astype(float)\n",
    "    return results\n",
    "def returnDailyLabels(a,b):\n",
    "    inputs = concatData(a, b)\n",
    "    results = inputs[1:,0].reshape(-1,1).astype(float)\n",
    "    return results\n",
    "def returnWeeklyLabels(a,b):\n",
    "    results = []\n",
    "    inputs = concatData(a, b)\n",
    "    for i in range(1, 1142):\n",
    "        results.append((inputs[i:i+7,0]).astype(float))\n",
    "    results = np.array(results)\n",
    "    return results\n",
    "def returnMonthlyLabels(a,b):\n",
    "    results = []\n",
    "    inputs = concatData(a, b)\n",
    "    for i in range(1, 1119):\n",
    "        results.append((inputs[i:i+30,0]).astype(float))\n",
    "    results = np.array(results)\n",
    "    return results\n",
    "def reverseData(arr):\n",
    "    temp = [[0] * len(arr[0]) for _ in range(len(arr))]\n",
    "    for i in range(len(arr)):\n",
    "        temp[i] = arr[len(arr)-1-i]\n",
    "    return temp\n",
    "def scaleData(a):\n",
    "    scaler = MinMaxScaler()\n",
    "    scale_cols = [0]\n",
    "    df_scaled = scaler.fit_transform(a[scale_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52844246",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS = Stock('005930')\n",
    "SK = Stock('000660')\n",
    "DW=Stock('049770')\n",
    "SFA=Stock('056190')\n",
    "GB=Stock('024110')\n",
    "\n",
    "sa=SS.priceList()\n",
    "sk=SK.priceList()\n",
    "dw=DW.priceList()\n",
    "sf=SFA.priceList()\n",
    "gb=GB.priceList()\n",
    "sadata=SS.idxNorm()\n",
    "skdata=SK.idxNorm()\n",
    "dwdata=DW.idxNorm()\n",
    "sfdata=SFA.idxNorm()\n",
    "gbdata=GB.idxNorm()\n",
    "print(sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffde786e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dtrain_inputs = []\n",
    "dtrain_labels = []\n",
    "dtrain_inputs.append(returnInputs(sa, sadata))\n",
    "dtrain_inputs.append(returnInputs(sk, skdata))\n",
    "dtrain_inputs.append(returnInputs(dw, dwdata))\n",
    "dtrain_inputs.append(returnInputs(sf, sfdata))\n",
    "dtrain_inputs.append(returnInputs(gb, gbdata))\n",
    "dtrain_inputs = np.array(dtrain_inputs)\n",
    "\n",
    "dtrain_labels.append(returnDailyLabels(sa, sadata))\n",
    "dtrain_labels.append(returnDailyLabels(sk, skdata))\n",
    "dtrain_labels.append(returnDailyLabels(dw, dwdata))\n",
    "dtrain_labels.append(returnDailyLabels(sf, sfdata))\n",
    "dtrain_labels.append(returnDailyLabels(gb, gbdata))\n",
    "dtrain_labels = np.array(dtrain_labels)\n",
    "print(dtrain_labels, dtrain_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186774dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtrain_inputs = []\n",
    "wtrain_labels = []\n",
    "wtrain_inputs.append(returnInputs(sa, sadata))\n",
    "wtrain_inputs.append(returnInputs(sk, skdata))\n",
    "wtrain_inputs.append(returnInputs(dw, dwdata))\n",
    "wtrain_inputs.append(returnInputs(sf, sfdata))\n",
    "wtrain_inputs.append(returnInputs(gb, gbdata))\n",
    "wtrain_inputs = np.array(wtrain_inputs)\n",
    "wtrain_inputs = wtrain_inputs[:,:1141,:]\n",
    "\n",
    "wtrain_labels.append(returnWeeklyLabels(sa, sadata))\n",
    "wtrain_labels.append(returnWeeklyLabels(sk, skdata))\n",
    "wtrain_labels.append(returnWeeklyLabels(dw, dwdata))\n",
    "wtrain_labels.append(returnWeeklyLabels(sf, sfdata))\n",
    "wtrain_labels.append(returnWeeklyLabels(gb, gbdata))\n",
    "wtrain_labels = np.array(wtrain_labels)\n",
    "print(wtrain_labels.shape, wtrain_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e09c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrain_inputs = []\n",
    "mtrain_labels = []\n",
    "mtrain_inputs.append(returnInputs(sa, sadata))\n",
    "mtrain_inputs.append(returnInputs(sk, skdata))\n",
    "mtrain_inputs.append(returnInputs(dw, dwdata))\n",
    "mtrain_inputs.append(returnInputs(sf, sfdata))\n",
    "mtrain_inputs.append(returnInputs(gb, gbdata))\n",
    "mtrain_inputs = np.array(mtrain_inputs)\n",
    "mtrain_inputs = mtrain_inputs[:,:1118,:]\n",
    "\n",
    "mtrain_labels.append(returnMonthlyLabels(sa, sadata))\n",
    "mtrain_labels.append(returnMonthlyLabels(sk, skdata))\n",
    "mtrain_labels.append(returnMonthlyLabels(dw, dwdata))\n",
    "mtrain_labels.append(returnMonthlyLabels(sf, sfdata))\n",
    "mtrain_labels.append(returnMonthlyLabels(gb, gbdata))\n",
    "mtrain_labels = np.array(mtrain_labels)\n",
    "print(mtrain_labels.shape, mtrain_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe70c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmodel = Sequential([\n",
    "    layers.LSTM(512, input_shape=(dtrain_inputs.shape[1],dtrain_inputs.shape[2]), return_sequences=True),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(1, activation = 'relu')\n",
    "])\n",
    "\n",
    "dmodel.compile(loss='mse',optimizer='adam')\n",
    "dmodel.summary()\n",
    "dmodel.fit(dtrain_inputs, dtrain_labels,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f131df",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmodel = Sequential([\n",
    "    layers.LSTM(512, input_shape=(wtrain_inputs.shape[1],wtrain_inputs.shape[2]), return_sequences=True),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(7, activation = 'relu')\n",
    "])\n",
    "\n",
    "wmodel.compile(loss='mse',optimizer='adam')\n",
    "wmodel.summary()\n",
    "wmodel.fit(wtrain_inputs, wtrain_labels,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da25535",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmodel = Sequential([\n",
    "    layers.LSTM(512, input_shape=(mtrain_inputs.shape[1],mtrain_inputs.shape[2]), return_sequences=True),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(30, activation = 'relu')\n",
    "])\n",
    "\n",
    "mmodel.compile(loss='mse',optimizer='adam')\n",
    "mmodel.summary()\n",
    "mmodel.fit(mtrain_inputs, mtrain_labels,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1485250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('stockmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b36b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "a.append(reverseData(returnInputs(sa, sadata)))\n",
    "a = np.array(a)\n",
    "print(a)\n",
    "model.predict(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
