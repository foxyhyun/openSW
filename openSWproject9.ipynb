{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5514cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import openpyxl\n",
    "import urllib\n",
    "from urllib import parse\n",
    "import lxml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import import_ipynb\n",
    "from Stock import Stock\n",
    "import processData\n",
    "import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52844246",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20248\\714605415.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mGB\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mStock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'024110'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msa\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpriceamount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0msk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpriceamount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpriceamount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\바탕 화면\\forecasting\\Stock.ipynb\u001b[0m in \u001b[0;36mpriceamount\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "SS = Stock('005930')\n",
    "SK = Stock('000660')\n",
    "DW=Stock('049770')\n",
    "SFA=Stock('056190')\n",
    "GB=Stock('024110')\n",
    "\n",
    "sa=SS.priceamount()\n",
    "sk=SK.priceamount()\n",
    "dw=DW.priceamount()\n",
    "sf=SFA.priceamount()\n",
    "gb=GB.priceamount()\n",
    "sadata=SS.idxNorm()\n",
    "skdata=SK.idxNorm()\n",
    "dwdata=DW.idxNorm()\n",
    "sfdata=SFA.idxNorm()\n",
    "gbdata=GB.idxNorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffde786e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5.09 ]\n",
      "  [ 5.16 ]\n",
      "  [ 5.13 ]\n",
      "  ...\n",
      "  [ 5.66 ]\n",
      "  [ 5.53 ]\n",
      "  [ 5.55 ]]\n",
      "\n",
      " [[ 8.34 ]\n",
      "  [ 8.58 ]\n",
      "  [ 8.61 ]\n",
      "  ...\n",
      "  [ 7.6  ]\n",
      "  [ 7.5  ]\n",
      "  [ 7.57 ]]\n",
      "\n",
      " [[24.75 ]\n",
      "  [24.5  ]\n",
      "  [24.05 ]\n",
      "  ...\n",
      "  [16.   ]\n",
      "  [15.7  ]\n",
      "  [15.6  ]]\n",
      "\n",
      " [[ 3.475]\n",
      "  [ 3.385]\n",
      "  [ 3.52 ]\n",
      "  ...\n",
      "  [ 3.74 ]\n",
      "  [ 3.64 ]\n",
      "  [ 3.53 ]]\n",
      "\n",
      " [[ 1.675]\n",
      "  [ 1.675]\n",
      "  [ 1.695]\n",
      "  ...\n",
      "  [ 1.   ]\n",
      "  [ 0.982]\n",
      "  [ 0.946]]] (5, 1147, 1)\n"
     ]
    }
   ],
   "source": [
    "dtrain_inputs = []\n",
    "dtrain_labels = []\n",
    "dtrain_inputs.append(returnInputs(sa, sadata))\n",
    "dtrain_inputs.append(returnInputs(sk, skdata))\n",
    "dtrain_inputs.append(returnInputs(dw, dwdata))\n",
    "dtrain_inputs.append(returnInputs(sf, sfdata))\n",
    "dtrain_inputs.append(returnInputs(gb, gbdata))\n",
    "dtrain_inputs = np.array(dtrain_inputs)\n",
    "\n",
    "dtrain_labels.append(returnDailyLabels(sa, sadata))\n",
    "dtrain_labels.append(returnDailyLabels(sk, skdata))\n",
    "dtrain_labels.append(returnDailyLabels(dw, dwdata))\n",
    "dtrain_labels.append(returnDailyLabels(sf, sfdata))\n",
    "dtrain_labels.append(returnDailyLabels(gb, gbdata))\n",
    "dtrain_labels = np.array(dtrain_labels)\n",
    "print(dtrain_labels, dtrain_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186774dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7) [[ 5.91   5.81   5.79   5.81   5.66   5.53   5.55 ]\n",
      " [ 7.92   7.78   7.7    7.7    7.6    7.5    7.57 ]\n",
      " [16.15  16.1   16.1   16.05  16.    15.7   15.6  ]\n",
      " [ 3.77   3.78   3.83   3.835  3.74   3.64   3.53 ]\n",
      " [ 1.11   1.11   1.105  1.12   1.     0.982  0.946]]\n"
     ]
    }
   ],
   "source": [
    "wtrain_inputs = []\n",
    "wtrain_labels = []\n",
    "wtrain_inputs.append(returnInputs(sa, sadata))\n",
    "wtrain_inputs.append(returnInputs(sk, skdata))\n",
    "wtrain_inputs.append(returnInputs(dw, dwdata))\n",
    "wtrain_inputs.append(returnInputs(sf, sfdata))\n",
    "wtrain_inputs.append(returnInputs(gb, gbdata))\n",
    "wtrain_inputs = np.array(wtrain_inputs)\n",
    "wtrain_inputs = wtrain_inputs[:,:1141,:]\n",
    "\n",
    "wtrain_labels.append(returnWeeklyLabels(sa, sadata))\n",
    "wtrain_labels.append(returnWeeklyLabels(sk, skdata))\n",
    "wtrain_labels.append(returnWeeklyLabels(dw, dwdata))\n",
    "wtrain_labels.append(returnWeeklyLabels(sf, sfdata))\n",
    "wtrain_labels.append(returnWeeklyLabels(gb, gbdata))\n",
    "wtrain_labels = np.array(wtrain_labels)\n",
    "wtrain_labels = wtrain_labels[:,-1,:]\n",
    "print(wtrain_labels.shape, wtrain_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e08e09c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30) [[ 6.14   6.06   6.1    6.14   6.1    6.01   6.06   6.22   6.26   6.04\n",
      "   6.03   5.92   5.89   5.92   6.04   5.95   5.97   6.05   5.93   5.95\n",
      "   5.95   5.86   5.8    5.91   5.81   5.79   5.81   5.66   5.53   5.55 ]\n",
      " [ 8.63   8.52   8.52   8.69   8.51   8.31   8.37   8.5    8.47   8.19\n",
      "   8.1    8.1    7.89   7.88   8.15   8.11   8.23   8.18   8.02   7.84\n",
      "   7.9    7.83   7.8    7.92   7.78   7.7    7.7    7.6    7.5    7.57 ]\n",
      " [13.85  13.95  14.05  14.    14.05  13.6   13.7   13.85  14.05  14.25\n",
      "  14.2   14.2   14.15  14.25  14.4   14.7   14.55  14.65  14.7   14.75\n",
      "  14.75  14.65  15.65  16.15  16.1   16.1   16.05  16.    15.7   15.6  ]\n",
      " [ 3.9    3.97   4.07   4.005  3.97   3.905  3.975  4.     3.935  3.885\n",
      "   3.905  3.805  3.785  3.775  3.82   3.69   3.71   3.765  3.755  3.685\n",
      "   3.695  3.61   3.635  3.77   3.78   3.83   3.835  3.74   3.64   3.53 ]\n",
      " [ 1.09   1.1    1.095  1.105  1.105  1.095  1.105  1.12   1.12   1.12\n",
      "   1.125  1.11   1.09   1.085  1.105  1.105  1.11   1.11   1.1    1.09\n",
      "   1.105  1.11   1.115  1.11   1.11   1.105  1.12   1.     0.982  0.946]]\n"
     ]
    }
   ],
   "source": [
    "mtrain_inputs = []\n",
    "mtrain_labels = []\n",
    "mtrain_inputs.append(returnInputs(sa, sadata))\n",
    "mtrain_inputs.append(returnInputs(sk, skdata))\n",
    "mtrain_inputs.append(returnInputs(dw, dwdata))\n",
    "mtrain_inputs.append(returnInputs(sf, sfdata))\n",
    "mtrain_inputs.append(returnInputs(gb, gbdata))\n",
    "mtrain_inputs = np.array(mtrain_inputs)\n",
    "mtrain_inputs = mtrain_inputs[:,:1118,:]\n",
    "\n",
    "mtrain_labels.append(returnMonthlyLabels(sa, sadata))\n",
    "mtrain_labels.append(returnMonthlyLabels(sk, skdata))\n",
    "mtrain_labels.append(returnMonthlyLabels(dw, dwdata))\n",
    "mtrain_labels.append(returnMonthlyLabels(sf, sfdata))\n",
    "mtrain_labels.append(returnMonthlyLabels(gb, gbdata))\n",
    "mtrain_labels = np.array(mtrain_labels)\n",
    "mtrain_labels = mtrain_labels[:,-1,:]\n",
    "print(mtrain_labels.shape, mtrain_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe70c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1147, 512)         1069056   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               328192    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,397,377\n",
      "Trainable params: 1,397,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 122.8327 - mae: 8.2364\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 77.2663 - mae: 5.7697\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 56.8146 - mae: 4.7450\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 47.5081 - mae: 4.6267\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 42.0241 - mae: 4.5366\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 38.8330 - mae: 4.4420\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 35.5261 - mae: 4.3711\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 29.7753 - mae: 3.8258\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 26.1835 - mae: 3.0292\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 23.2090 - mae: 3.0957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f8ce7e850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmodel = Sequential([\n",
    "    layers.LSTM(512, input_shape=(dtrain_inputs.shape[1],dtrain_inputs.shape[2]), return_sequences=True),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(1, activation = 'relu')\n",
    "])\n",
    "\n",
    "dmodel.compile(loss='mse',optimizer='adam', metrics='mae')\n",
    "dmodel.summary()\n",
    "dmodel.fit(dtrain_inputs, dtrain_labels,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f131df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 1141, 512)         1069056   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               328192    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,398,151\n",
      "Trainable params: 1,398,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 71.4373\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 63.5891\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 56.1074\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 49.9731\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 45.0328\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 41.0027\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 37.6601\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 34.7752\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32.3315\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 30.6172\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 28.9715\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 27.8426\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 26.8565\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 25.9274\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 25.0539\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.2688\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 23.5711\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.5729\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.8048\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.2371\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.6622\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.0792\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 19.5035\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.9512\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.4326\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.9428\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.4166\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.7545\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.8556\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.1600\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.7165\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.2683\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.8874\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.4737\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.1490\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.8042\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.4577\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.1193\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 12.7941\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 12.4632\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 12.2973\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.9635\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.6218\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.1232\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.7689\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.5127\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.2533\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.9805\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6880\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.3949\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.0867\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.7510\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4789\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.2157\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.9705\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.7310\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5032\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.3198\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.1002\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.8652\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.7225\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.6228\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.2596\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.0869\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.8772\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.6975\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.5674\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.3578\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 5.1686\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 4.9973\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.8336\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.6782\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.5252\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.3771\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.2314\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.0882\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3.9627\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3.8257\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3.6990\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3.5730\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3.4461\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3.3259\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3.2077\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3.0950\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.9876\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.8805\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.7807\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.6801\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.5836\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.4911\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.4014\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.3140\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.2286\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.1461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0663\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.9889\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.9138\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.8410\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.7707\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.7026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20fb4c656d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmodel = Sequential([\n",
    "    layers.LSTM(512, input_shape=(wtrain_inputs.shape[1],wtrain_inputs.shape[2]), return_sequences=True),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(7, activation = 'relu')\n",
    "])\n",
    "\n",
    "wmodel.compile(loss='mse',optimizer='adam')\n",
    "wmodel.summary()\n",
    "wmodel.fit(wtrain_inputs, wtrain_labels,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0da25535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 1118, 512)         1069056   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 256)               787456    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                7710      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,864,222\n",
      "Trainable params: 1,864,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 65.6201\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 58.6608\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 52.7546\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 48.0625\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 44.4847\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 41.2695\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 38.3510\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 35.9567\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 33.8114\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 32.1643\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 30.7439\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 29.4710\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 28.2974\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 27.1812\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 25.5180\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 24.6365\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 23.9038\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 22.9846\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 22.0490\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 21.2618\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.4306\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19.4770\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.7653\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.0263\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.1866\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.4002\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.6598\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.9918\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.3218\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.7447\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.1482\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 12.5999\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 12.0966\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.6426\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.1610\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.7607\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.3479\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.9907\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.6502\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.4453\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.3881\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.6553\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.4706\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.1561\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.9472\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.8401\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.5370\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.3403\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.1587\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.9613\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.7964\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.6334\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.4912\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.3481\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.2154\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.0873\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.9770\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.8710\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.7699\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.6710\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 5.5906\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.5045\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.4312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.3560\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.2835\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.2279\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.1656\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.1123\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.0633\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.0129\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.9701\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.9308\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.8920\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.8588\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.8256\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 4.7948\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.7688\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 4.7427\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.7172\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.6956\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.6752\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.6549\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.6376\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.6213\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.6048\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.5901\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.5775\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.5653\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.5532\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.5423\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.5330\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.5240\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.5151\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.5071\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 4.5030\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.4957\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.4873\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.4817\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.4766\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.4716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20fb966e850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmodel = Sequential([\n",
    "    layers.LSTM(512, input_shape=(mtrain_inputs.shape[1],mtrain_inputs.shape[2]), return_sequences=True),\n",
    "    layers.LSTM(256),\n",
    "    layers.Dense(30, activation = 'relu')\n",
    "])\n",
    "\n",
    "mmodel.compile(loss='mse',optimizer='adam')\n",
    "mmodel.summary()\n",
    "mmodel.fit(mtrain_inputs, mtrain_labels,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc21feca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5.26        2.310472   -0.14501075 ...  0.07745662 -0.58799426\n",
      "    0.15273633]\n",
      "  [ 5.09        1.6128305   0.06160386 ... -0.06111653  2.42368367\n",
      "    0.13651005]\n",
      "  [ 5.16        1.3905263   0.06160386 ... -0.06111653  2.42368367\n",
      "    0.13651005]\n",
      "  ...\n",
      "  [ 5.95        0.7696187   0.42443926 ... -0.20876186  2.02212661\n",
      "   -0.18861003]\n",
      "  [ 5.86        0.9284761   0.42443926 ... -0.20876186  2.02212661\n",
      "   -0.18861003]\n",
      "  [ 5.8         1.0356971   0.42443926 ... -0.20876186  2.02212661\n",
      "   -0.18861003]]]\n",
      "1/1 [==============================] - 1s 538ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.913666 , 5.860912 , 5.7413707, 5.812927 , 5.650694 , 5.60696  ,\n",
       "        5.5205317]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[]\n",
    "a.append(returnInputs(sa, sadata))\n",
    "a = np.array(a)\n",
    "a = a[:,:1141,:]\n",
    "print(a)\n",
    "wmodel.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1485250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmodel.save('dailymodel.h5')\n",
    "wmodel.save('weeklymodel.h5')\n",
    "mmodel.save('monthlymodel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
